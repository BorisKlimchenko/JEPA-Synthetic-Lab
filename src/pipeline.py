import torch
import json
import os
import logging
import random
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Optional, Dict

# –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler
from diffusers.utils import export_to_gif
from google.colab import userdata

# --- 1. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - [JEPA-CORE] - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger(__name__)

# --- 2. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
@dataclass
class EngineConfig:
    """–ù–µ–∏–∑–º–µ–Ω—è–µ–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–µ–π –∏ –º–æ–¥–µ–ª–µ–π."""
    base_model_id: str = "SG161222/Realistic_Vision_V5.1_noVAE"
    motion_adapter_id: str = "guoyww/animatediff-motion-adapter-v1-5-2"
    prompts_path: str = "configs/prompts.json"
    output_dir: str = "renders"

# --- 3. –°–¢–†–ê–¢–ï–ì–ò–ò –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò ---

class OptimizationStrategy(ABC):
    @abstractmethod
    def apply(self, pipe: AnimateDiffPipeline):
        pass

class HighPerformanceStrategy(OptimizationStrategy):
    """–î–ª—è –º–æ—â–Ω—ã—Ö GPU (>20GB VRAM)."""
    def apply(self, pipe: AnimateDiffPipeline):
        logger.info("üöÄ Strategy: HIGH PERFORMANCE. All systems in VRAM.")
        pipe.enable_vae_slicing()

class SurvivalStrategy(OptimizationStrategy):
    """–î–ª—è —Å–ª–∞–±—ã—Ö GPU (<16GB VRAM)."""
    def apply(self, pipe: AnimateDiffPipeline):
        logger.info("üõ°Ô∏è Strategy: SURVIVAL MODE. Aggressive offloading enabled.")
        pipe.enable_model_cpu_offload()
        pipe.enable_vae_slicing()
        pipe.enable_vae_tiling()

def detect_strategy() -> OptimizationStrategy:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –∂–µ–ª–µ–∑–∞."""
    if not torch.cuda.is_available():
        logger.warning("‚ö†Ô∏è CUDA not found! CPU mode is not supported efficiently.")
        return SurvivalStrategy()

    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
    device_name = torch.cuda.get_device_name(0)
    
    logger.info(f"üñ•Ô∏è Hardware Detected: {device_name} ({vram_gb:.1f} GB)")

    if vram_gb > 20.0:
        return HighPerformanceStrategy()
    else:
        return SurvivalStrategy()

# --- 4. –û–°–ù–û–í–ù–û–ô –î–í–ò–ñ–û–ö ---

class LatentMotionEngine:
    """
    SMA-01 Core Engine.
    –£–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–≥—Ä—É–∑–∫–æ–π, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –∏ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–æ–º.
    """
    
    def __init__(self, hf_token: Optional[str] = None):
        logger.info("‚öôÔ∏è Initializing Latent Motion Engine...")
        
        self.config = EngineConfig()
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.dtype = torch.float16 if self.device == "cuda" else torch.float32
        
        # –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        self.token = hf_token or self._fetch_token()
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤
        self.prompts_db = self._load_prompts()
        
        # 2. –í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        self.strategy = detect_strategy()
        
        # 3. –°–±–æ—Ä–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
        self.pipe = self._build_pipeline()

    def _fetch_token(self) -> Optional[str]:
        try:
            return userdata.get('HF_TOKEN')
        except Exception:
            logger.warning("‚ö†Ô∏è HF_TOKEN not found. Using public access.")
            return None

    def _load_prompts(self) -> Dict:
        # –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞ –ø—É—Ç—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º
        if not os.path.exists(self.config.prompts_path):
            logger.warning(f"‚ùå Config {self.config.prompts_path} not found.")
            return {"scenes": {}}
            
        with open(self.config.prompts_path, 'r') as f:
            data = json.load(f)
        return data

    def _build_pipeline(self) -> AnimateDiffPipeline:
        logger.info("üîå Loading Neural Network weights...")
        
        adapter = MotionAdapter.from_pretrained(
            self.config.motion_adapter_id,
            torch_dtype=self.dtype,
            token=self.token
        )

        pipe = AnimateDiffPipeline.from_pretrained(
            self.config.base_model_id,
            motion_adapter=adapter,
            torch_dtype=self.dtype,
            token=self.token
        )

        pipe.scheduler = EulerDiscreteScheduler.from_config(
            pipe.scheduler.config, 
            timestep_spacing="trailing", 
            beta_schedule="linear"
        )

        self.strategy.apply(pipe)
        return pipe

    def render(self, 
               scene_name: str, 
               num_frames: int = 16, 
               seed: int = -1) -> str:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
        """
        # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è
        if scene_name not in self.prompts_db.get('scenes', {}):
            raise ValueError(f"‚ùå Scene '{scene_name}' not found in DB.")
            
        scene_data = self.prompts_db['scenes'][scene_name]
        
        # 2. –ß—Ç–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏–∑ JSON
        sys_config = self.prompts_db.get('system_settings', {})
        width = sys_config.get('width', 512)
        height = sys_config.get('height', 512)
        
        logger.info(f"üìê Resolution set to: {width}x{height}")

        # 3. –°–∏–¥ (Seed)
        if seed == -1:
            seed = random.randint(0, 2**32 - 1)
            logger.info(f"üé≤ Seed Auto-Generated: {seed}")
        else:
            logger.info(f"üîí Using Fixed Seed: {seed}")
            
        generator = torch.Generator(self.device).manual_seed(seed)
        
        # 4. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
        logger.info(f"üé¨ Rendering: {scene_data.get('description', 'Unknown')}")
        
        output = self.pipe(
            prompt=scene_data['positive'],
            negative_prompt=scene_data.get('negative', ""), 
            num_frames=num_frames,
            guidance_scale=7.5,
            num_inference_steps=35,
            generator=generator,
            width=width,
            height=height
        )
        
        # 5. –≠–∫—Å–ø–æ—Ä—Ç
        os.makedirs(self.config.output_dir, exist_ok=True)
        filename = f"{self.config.output_dir}/{scene_name}_{seed}.gif"
        export_to_gif(output.frames[0], filename)
        
        logger.info(f"üíæ Artifact saved: {filename}")
        return filename

# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
if __name__ == "__main__":
    print("--- JEPA CORE CHECK ---")
    try:
        engine = LatentMotionEngine()
        print("‚úÖ Status: ONLINE.")
    except Exception as e:
        print(f"‚ùå Status: ERROR: {e}")